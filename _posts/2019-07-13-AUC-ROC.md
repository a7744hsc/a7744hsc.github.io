---
layout: post
title:  "白话详解ROC&AUC"
date:   2019-07-13 01:00:00 +0800
categories: Machine Learning
---

本文的[参考资料](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)


搞机器学习的人一定频繁的听到ROC，AUC或者AUC-ROC，但这个概念又不向准确率召回率那么直观容易理解，给我带来了小小的困扰，这里就系统的学习下这两个概念。

ROC即Receiver Operating Characteristics, 中文一般翻译成“受试者工作特性曲线”。这是一种度量二分类性能的指标。直观来讲，ROC曲线表示的是`模型在准确识别正例`和`不把负例错误的识别成正例`这两种能力之间`相互制约的关系`(当我们需要“宁可错杀一千，也不放过一个”的时候，ROC能告诉你到底要错杀多少才能一个坏人都不放过)。

在详细解释ROC之前需要先解释两个前置概念，即TPR（True Positive Rate）和FPR（False Positive Rate）。

TPR 真正率（召回率）：找出的正例占所有的正例的比率。比如有10人换糖尿病，通过模型确诊了其中的8个，则 TPR=0.8

FPR 假正率： 即所有的负例中分类错误的比例。比如有十个人没有患糖尿病（这里把患病作为正例），但是模型错误的将其中一个人误诊为患病，则FPR=0.1

ROC即为以FPR为横轴，以TPR为纵轴的一条曲线（如下图），有了这条曲线你就能清楚的回答下面这些问题
1. 知道在可以放过1%坏人的情况下要错杀多少好人？
2. 在最多能错杀1%好人的情况下会放掉多少坏人？
3. 当糖尿病的误诊率不能高于5%时，会有多少有病的患者被错误判断成无病？

![Auc-roc](/images/AUC.png "Auc-roc")

ROC曲线很直观，也方便使用。但他有个致命的弱点，就是无法对比多个模型的性能。AUC就是为了解决这个问题而出现的。

AUC，即 Area Under Curve（曲线下面积）。严格上讲，“AUC”并没有意义，因为它可以是你随手绘制的一条曲线的曲线下面积，不过在机器学习领域一般默认AUC就是指AUC-ROC（AUROC也是同样的意思）。 AUC-ROC代表一个模型对正负例的区分能力（既不放过一个，也不错杀一个），他的值在0和1之间，越大代表模型性能越好。

从上图中很容易直观的感受到什么是AUC-ROC（途中笔误写成了AOC）。知道了AUC-ROC，还需要知道几个典型值，当AUC-ROC的值接近1的时候，代表模型效果很好；当值为0的时候代表模型总是颠倒黑白，把好的说成坏的，坏的说成好的；当值为0.5时可以认为模型知识随机做出判断，不具备区分能力。

