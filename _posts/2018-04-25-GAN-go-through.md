---
layout: post
title:  "生成对抗网络"
date:   2018-04-25 11:00:00 +0800
categories: Machine Learning
---
[生成对抗网络论文链接]（https://arxiv.org/pdf/1406.2661.pdf）

## 生成对抗网络解决了什么问题？
神经网络主要分为生成网络和判别网络，在生成对抗网络产生之前，生成网络并没有什么成果。Goodfellow认为这是主要是由于生成网络的结果难以确定（没有合适的损失函数）。生成对抗网络直接跳过了损失函数这一步，通过两个网络相互制约来实现训练过程。原论文把生成对抗网络中的生成网络G和判别网络D分别比喻成假币团伙和警察，G努力使假币和真币更接近，而D则努力把假币从真币中区分出来。通过G和D的对抗，最终使得两者的模型准确度都得到提升。

## 生成对抗网络结构
![GAN structure](/images/GANs.png?style=center "GAN structure")

下图是一个以手写数字生成为目标的原始的GAN网络结构，可以它由Generator生成器和Discriminator判别器组成。生成器用于从噪音中生成一幅手写数字的图片，而判别器则努力将训练集图片和生成器生成的假图片区分开来。可以证明，当网络的能力足够的时候，生成器最终会生成和训练集特征相同的图像。具体的训练步骤如下(来自原论文中伪代码)

```
 for num_of_training_iterations:
    for k_steps: #k在这里是超参数，代表每个迭代对判别器做几次优化
        从训练集中随机选取m幅图像
        随机选取（生成）m个噪声图片
        更新判别器参数（普通神经网络训练过程，例如交叉熵误差函数和随机梯度下降）
    
    随机选取m个噪声图片
    更新生成器参数
```

其实在GAN的论文中主要是提出了利用生成器和判别器相互制约的思路，而非详细的模型结构。上面的训练方法只是一种示例方法，生成器和判别器也不必是申请网络。

## 生成对抗网络的优势和劣势

论文原作者也思考了GAN的优势和劣势，下面是作者在论文中的总结，

CONs：

    1. 网络自由度太高，训练难度大
    2. 两个模型是分开更新的，所以带来了两个模型之间的同步问题。如果一个模型训练的过快，会影响另一个模型的训练。

PROs：

    1. 只使用反向传播即可完成训练，不使用何马尔可夫链来训练。
    2. GAN可以和大部分现有的生成网络算法相结合使用，提高性能。

从实际应用中，模型难以训练是困扰很多研究人员最大的问题，不过在论文发布（2014年）以来，大量GAN改进方法被提出，较好的解决了GAN中存在的问题，使得图像生成任务达到了可以商业应用的成熟度。


## 生成对抗网络主要应用举例

前面说了生成对抗网络经过几年的研究已经比较成熟，可以进行商业应用。下面就列举了几个比较有名的开源应用案例：

1. [zi2zi](https://github.com/kaonashi-tyc/zi2zi)：一个变换中文字体的应用，基于pix2pix

2. [iGAN](https://github.com/junyanz/iGAN)：我管他叫神笔马良，一个adobe和伯克利两盒发布的图像增强网络，能从简笔画生成一个真实度很高的图像。

3. [domain-transfer-network](https://github.com/yunjey/domain-transfer-network): 感觉和CNN中的风格迁移类似，实现的功能类似脸萌，可以从真实头像生成卡通头像

4. [neural-enhance](https://github.com/alexjc/neural-enhance): 将低分辨率图像处理成高分辨率图像，以后各种游戏炒冷饭，电影重制版的成本可以大大降低了。。。。

5. [deepfake](https://github.com/deepfakes/faceswap): 前一阵引起轩然大波的现象级应用，可以给视频换脸，应用场景很多。。。。。。多到不能细说

类似的应用还有很多，而且也达到了不错的效果。个人感觉GAN真的是一个很有钱途的领域。