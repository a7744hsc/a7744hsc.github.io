DL tips for Tips
======================

1. c++基础
2. python基础
3. svm 原理
    * 能够容忍异常值（outlier），对异常值
    * 在分类正确的情况下，最大化最近点的边缘
    svm有几个不同于线性分类器的特点：
    1. svm在分类时不以所有样本为依据进行划分，而是只考虑“支持向量”（“支持向量”听起来挺玄乎，
    其实向量就是样本，而支持向量就是从所有训练样本中选出的一个子集）。那么如何确定确定支持向量？，后文解答
    2. 普通线性分类器只要求能正确分类给定样本即可，但svm要求
4. logistic分类器，线性分类器
5. 决策树，随机森林，adaBoost
6. 经典算法
7. 红黑树(map的实现方式), b树，b+树
8. 算法，leetCode
9. 深度学习，卷积神经网络，前沿,生成对抗网络
10. tf,pyTorch,Caffe
11. attention mode, neural GPU    conv GRU  LSTM 



分割线
===============================
1. KNN 和k—means

KNN是分类，k-means是聚类。KNN通过找附近k个点的分类确定当前点类别，K-means将数据集聚集为k类。

2. ROC曲线（受试者工作特征曲线，receiver operating characteristic curve）

代表真正和假正的比例，横轴是假正占所有负类的比例，纵轴是真正占所有正类的比例。
召回率代表找到的True实例和总得True实例比值，准确度是真正比上所有预测为正的数量。

3. L1和L2正规化

L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择
L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合

4. 一类错误和二类错误，存伪 和 弃真

5. likelyhood 和probability的区别？

似然是结果得到参数的可能，概率是给定参数得到结果的可能。

6. 处理 imbalanced dataset

 能不能搜集更多数据，
 改变评价函数，用F1-score
 数据重新采样
 生成人造数据
 决策树对不平衡数据效果比较好

 7. 怎么处理缺失数据和异常数据？

 删除相应行 或者 填充缺失数据

8. 牛顿法和梯度下降区别

牛顿法收敛更快，但是计算更复杂

9. KNN是一种分类算法，KD树可以加速KNN运算，减少计算量。

10. maxpool 反向传播，非最大值梯度置0

11. SVM多分类， 多个二分类组合起来。

TO-DO
========
1. opencv读取优化？？？？？？？？？？？

2. 传统图像识别

3. BP推到，为什么参数不能初始化为0

4. RNN

5. GAN

6. xgBoost